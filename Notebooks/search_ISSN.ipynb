{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X06ZBTbY1KoE"
      },
      "source": [
        "This notebook search the related ISSN of each DOI in the COCI dataset. Since loading the entire dataset (30 GB unzipped) into memory is impossible, I will download each zipped folder (since it works remotely the process takes very little time), unzip it in Colab temporary storage and work this the individual .csv files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p_SHcPpJqXPE"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "import zipfile\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "from alive_progress import alive_bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfSrW9_ND0il"
      },
      "source": [
        "This function loads the cleaned Crossref dataset into a Pandas DataFrame and for each COCI .csv file it searches the ISSN of the DOIs. Then it creates a .json that records which ISSN has been mentioned by each citing DOI (i.e. the journals mentioned by a DOI) and how many times that has happened. \n",
        "With Colab RAM limit you can only run one single .csv, with Amazon SageMaker you might be able to process at least 5 .csv (12 vs 16 GB of ram)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-0MO6G13R6u6"
      },
      "outputs": [],
      "source": [
        "def get_issn_crossref(coci_files): #usando il database del crossref pulito e indicizzato\n",
        "  db_path = '/content/drive/MyDrive/Colab_Notebooks/opencitations/crossref_pulito_indexed.db'\n",
        "  connection = sqlite3.connect(db_path)\n",
        "  cursor = connection.cursor()\n",
        "  memory_dict = {}\n",
        "  set_not_found_citing = set()\n",
        "  set_not_found_cited = set()\n",
        "  for coci in coci_files:\n",
        "    print(coci)\n",
        "    with open(coci, 'r', encoding=\"utf8\") as csv_file: #read line by line the OC dataset and get citing and cited\n",
        "      csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "      row_count = sum(1 for row in csv_reader)  #count the number of rows for the progress bar\n",
        "      csv_file.seek(0) #reset file and interator\n",
        "      csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "      next(csv_reader)\n",
        "      with alive_bar(row_count,force_tty=True) as bar:\n",
        "        for row in csv_reader:\n",
        "          citing = row[1] \n",
        "          cited = row[2] \n",
        "          if citing in memory_dict.keys(): #check if citing has been already searched\n",
        "            rows = cursor.execute(\n",
        "                  \"SELECT doi, issn FROM articles WHERE doi = ?\",\n",
        "                          (cited,),).fetchall()  \n",
        "            if len(rows) != 0:\n",
        "              issn_cited = rows[0][1]\n",
        "              issn_cited = issn_cited.split(', ')[0].strip(\"'\").replace(\"-\", \"\") #we are getting only the e-issn instead of the printed one\n",
        "              if issn_cited in memory_dict[citing]['has_cited_n_times']:\n",
        "                memory_dict[citing]['has_cited_n_times'][issn_cited.strip(\"''\")] += 1\n",
        "              else:\n",
        "                memory_dict[citing]['has_cited_n_times'][issn_cited.strip(\"''\")] = 1\n",
        "            else:\n",
        "              continue\n",
        "          elif citing not in set_not_found_citing:\n",
        "            rows = cursor.execute(\n",
        "                  \"SELECT doi, issn FROM articles WHERE doi = ?\",\n",
        "                          (citing,),).fetchall() \n",
        "            if len(rows) != 0: \n",
        "              issn_citing = rows[0][1]\n",
        "              issn_citing = issn_citing.split(', ')[0].strip(\"'\").replace(\"-\", \"\")\n",
        "              if cited not in set_not_found_cited:\n",
        "                rows = cursor.execute(\n",
        "                  \"SELECT doi, issn FROM articles WHERE doi = ?\",\n",
        "                          (cited,),).fetchall()  \n",
        "                if len(rows) != 0:\n",
        "                  issn_cited = rows[0][1]\n",
        "                  issn_cited = issn_cited.split(', ')[0].strip(\"'\").replace(\"-\", \"\")\n",
        "                  memory_dict[citing] = {} \n",
        "                  memory_dict[citing]['issn'] = issn_citing.strip(\"''\")\n",
        "                  memory_dict[citing]['has_cited_n_times'] = {}\n",
        "                  memory_dict[citing]['has_cited_n_times'][issn_cited.strip(\"''\")] = 1\n",
        "                else:\n",
        "                  set_not_found_cited.add(cited)\n",
        "            else:\n",
        "              set_not_found_citing.add(citing)\n",
        "          bar()\n",
        "  with open('prova_db.json', 'w') as fp:\n",
        "    json.dump(list(memory_dict.values()), fp) #transform the dict in a list of dicts to reduce the output size \n",
        "\n",
        "#counters to check if everything works right\n",
        "  print('lenght of dict: ', len(memory_dict.keys()))\n",
        "  print('Number set not found citing: ', len(set_not_found_citing))\n",
        "  print('Number set not found cited: ', len(set_not_found_cited))\n",
        "\n",
        "  with open('citing_not_found.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile, delimiter=',')\n",
        "    for line in set_not_found_citing:\n",
        "      writer.writerow([line])\n",
        "  csvfile.close()\n",
        "  with open('cited_not_found.csv', 'w') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    for line in set_not_found_cited:\n",
        "      writer.writerow([line])\n",
        "  csvfile.close()\n",
        "\n",
        "  connection.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUjl0S4xW3Ry",
        "outputId": "fcc9570b-09ed-4f7d-aa9b-8df8d11f8887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/opencitationsunzipped/2021-07-06T163745_1_3.csv\n",
            "|███████████████████████████████████████▊⚠︎ (!) 9924912/10000001 [99%] in 1:44:59.7 (1575.47/s)                          \n",
            "/content/opencitationsunzipped/2021-07-06T163745_0_5.csv\n",
            "|███████████████████████████████████████▊⚠︎ (!) 9106152/9174360 [99%] in 1:38:57.3 (1533.72/s)                           \n",
            "/content/opencitationsunzipped/2021-07-06T163745_1_2.csv\n",
            "|███████████████████████████████████████▉⚠︎ (!) 9960590/10000001 [100%] in 1:40:35.0 (1650.48/s)                         \n",
            "/content/opencitationsunzipped/2021-07-06T163745_2_3.csv\n",
            "|███████████████████████████████████     | ▅▇▇ 8751673/10000001 [88%] in 1:41:41 (1434.5/s, eta: 14:30) "
          ]
        }
      ],
      "source": [
        "get_issn_crossref([r'E:/opencitation/6741422/2020-11-22T17_48_01_1-3/'+el for el in os.listdir('E:/opencitation/6741422/2020-11-22T17_48_01_1-3/') if '.csv' in el])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q2vGJg1XFLD",
        "outputId": "4be9e3f5-81c9-43db-967a-7591fb2691f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'issn': '10242422', 'has_cited_n_times': {'00221155': 2, '09608524': 9, '00218561': 3, '12332356': 1, '1369703X': 1, '14641801': 1, '01410229': 1, '02786915': 1, '01460749': 1, '15178382': 1, '07349750': 2, '13645072': 1, '00448486': 1, '09239820': 2, '09242244': 1, '01681605': 1, '10504648': 1, '00221147': 1, '00063444': 1, '03088146': 1, '01757598': 1, '02732289': 1, '13595113': 1, '13811177': 1, '1319562X': 1, '00223573': 1, '16180240': 1, '20701667': 1, '13369075': 1, '18772641': 1, '10286276': 1, '2193567X': 1, '21615063': 1, '22126708': 1, '03781135': 1, '23269162': 1, '00401706': 1}}\n"
          ]
        }
      ],
      "source": [
        "with open('/content/prova_db.json', 'r') as fp:\n",
        "  memory_dict = json.load(fp)\n",
        "  for el in memory_dict:\n",
        "    print(el)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzYenudDnY05",
        "outputId": "55f7cba8-9391-43e4-94ed-e28b895a571e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/opencitationsunzipped/2021-11-15T031921_3_1.csv\n",
            "|███████████████████████████████████████▊⚠︎ (!) 9588020/9640790 [99%] in 1:02:06.6 (2572.85/s)                           \n",
            "/content/opencitationsunzipped/2021-11-15T031921_2_1.csv\n",
            "|███████████████████████████████████████▋⚠︎ (!) 9558581/9636140 [99%] in 37:38.0 (4233.20/s)                             \n",
            "/content/opencitationsunzipped/2021-11-15T031921_1_1.csv\n",
            "|███████████████████████████████████████▋⚠︎ (!) 9561919/9644388 [99%] in 37:17.8 (4272.98/s)                             \n",
            "/content/opencitationsunzipped/2020-08-20T18:12:28_2.csv\n",
            "|███████████████████████████████████████▏⚠︎ (!) 1675676/1711749 [98%] in 13:44.7 (2031.94/s)                             \n",
            "/content/opencitationsunzipped/2020-08-20T18:12:28_1.csv\n",
            "|███████████████████████████████████████⚠︎| (!) 9749799/10000001 [97%] in 1:09:48.0 (2328.04/s)                          \n",
            "/content/opencitationsunzipped/2021-11-15T031921_4_1.csv\n",
            "|███████████████████████████████████████▋⚠︎ (!) 9555327/9641625 [99%] in 38:29.8 (4136.92/s)                             \n",
            "/content/opencitationsunzipped/2021-11-15T031921_0_1.csv\n",
            "|███████████████████████████████████████▋⚠︎ (!) 9559921/9648747 [99%] in 38:13.5 (4168.27/s)                             \n",
            "lenght of dict:  1722824\n",
            "Number set not found citing:  745108\n",
            "Number set not found cited:  173952\n"
          ]
        }
      ],
      "source": [
        "get_issn_crossref([r'/content/opencitationsunzipped/'+el for el in os.listdir('/content/opencitationsunzipped/') if '.csv' in el]) #experiment with multiple csvs (2 gb of zipped files)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "search_ISSN (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
